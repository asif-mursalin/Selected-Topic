{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d01892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/13 16:33:59 WARN Utils: Your hostname, lenovo-server resolves to a loopback address: 127.0.1.1; using 192.168.100.30 instead (on interface eno1)\n",
      "25/04/13 16:33:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/13 16:33:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/13 16:34:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with PySpark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in 40.93 seconds\n",
      "Filtered dataset: 200,948 users, 43,884 movies, 31,921,467 ratings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 22,343,094 ratings (69.99%)\n",
      "Validation set: 4,787,886 ratings (15.00%)\n",
      "Test set: 4,790,487 ratings (15.01%)\n",
      "Global mean rating: 3.5421\n",
      "Global Mean Model Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0590\n",
      "MAE: 0.8381\n",
      "\n",
      "Bias Model Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8788\n",
      "MAE: 0.6680\n",
      "Baseline models trained and evaluated in 17.70 seconds\n",
      "Training ALS model (rank=50, regParam=0.1, maxIter=10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8075\n",
      "MAE: 0.6276\n",
      "ALS model trained in 184.41 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/als_model\n",
      "\n",
      "ALS Model Performance on Test Set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8074\n",
      "MAE: 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example recommendations for user 148:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Once in a Summer (2006) - Predicted rating: 4.39\n",
      "2. Great Passage, The (Fune wo amu) (2013) - Predicted rating: 4.27\n",
      "3. Voice of Silence (2020) - Predicted rating: 4.04\n",
      "4. Warkop DKI Reborn: Jangkrik Boss! (2016) - Predicted rating: 3.96\n",
      "5. Dara O'Briain Crowd Tickler (2015) - Predicted rating: 3.88\n",
      "\n",
      "Model Performance Summary:\n",
      "                 RMSE       MAE\n",
      "Global Mean  1.059020  0.838117\n",
      "Bias Model   0.878832  0.668020\n",
      "ALS          0.807510  0.627639\n",
      "ALS (Test)   0.807448  0.627759\n",
      "\n",
      "Recommendation model pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# PySpark implementation of recommendation models for MovieLens 32M\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize Spark session - adjust memory settings based on your system\n",
    "def init_spark(app_name=\"MovieLens_Recommender\", memory=\"5g\"):\n",
    "    \"\"\"Initialize a Spark session with specified memory allocation\"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(app_name) \\\n",
    "        .config(\"spark.driver.memory\", memory) \\\n",
    "        .config(\"spark.executor.memory\", memory) \\\n",
    "        .config(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Set log level to reduce verbosity\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    \n",
    "    return spark\n",
    "\n",
    "# Load data using PySpark\n",
    "def load_data(spark, data_dir=\"ml-32m\", min_ratings=5):\n",
    "    \"\"\"\n",
    "    Load the MovieLens dataset into Spark DataFrames\n",
    "    \"\"\"\n",
    "    print(\"Loading data with PySpark...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load ratings\n",
    "    ratings_df = spark.read.csv(\n",
    "        os.path.join(data_dir, 'ratings.csv'),\n",
    "        header=True,\n",
    "        inferSchema=True\n",
    "    )\n",
    "    \n",
    "    # Load movies\n",
    "    movies_df = spark.read.csv(\n",
    "        os.path.join(data_dir, 'movies.csv'),\n",
    "        header=True,\n",
    "        inferSchema=True\n",
    "    )\n",
    "    \n",
    "    # Filter users and movies with minimum ratings\n",
    "    user_counts = ratings_df.groupBy(\"userId\").count().filter(col(\"count\") >= min_ratings)\n",
    "    active_users = user_counts.select(\"userId\")\n",
    "    \n",
    "    movie_counts = ratings_df.groupBy(\"movieId\").count().filter(col(\"count\") >= min_ratings)\n",
    "    active_movies = movie_counts.select(\"movieId\")\n",
    "    \n",
    "    # Join to get filtered ratings\n",
    "    filtered_ratings = ratings_df.join(active_users, \"userId\") \\\n",
    "                               .join(active_movies, \"movieId\")\n",
    "    \n",
    "    # Get stats about the filtered dataset\n",
    "    n_users = active_users.count()\n",
    "    n_movies = active_movies.count()\n",
    "    n_ratings = filtered_ratings.count()\n",
    "    \n",
    "    print(f\"Data loaded in {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Filtered dataset: {n_users:,} users, {n_movies:,} movies, {n_ratings:,} ratings\")\n",
    "    \n",
    "    return filtered_ratings, movies_df, n_users, n_movies\n",
    "\n",
    "# Convert movie genres to feature columns\n",
    "def process_movie_features(spark, movies_df):\n",
    "    \"\"\"Extract and process movie features including genres\"\"\"\n",
    "    \n",
    "    # Extract year from title\n",
    "    movies_df = movies_df.withColumn(\n",
    "        \"year\", \n",
    "        movies_df[\"title\"].substr(-5, 4).cast(IntegerType())\n",
    "    )\n",
    "    \n",
    "    # Get all unique genres\n",
    "    all_genres = set()\n",
    "    for genres in movies_df.select(\"genres\").rdd.flatMap(lambda x: x).collect():\n",
    "        all_genres.update(genres.split('|'))\n",
    "    \n",
    "    if '(no genres listed)' in all_genres:\n",
    "        all_genres.remove('(no genres listed)')\n",
    "    \n",
    "    # Create genre feature columns\n",
    "    for genre in all_genres:\n",
    "        movies_df = movies_df.withColumn(\n",
    "            f\"genre_{genre}\", \n",
    "            (col(\"genres\").contains(genre)).cast(IntegerType())\n",
    "        )\n",
    "    \n",
    "    return movies_df\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "def train_val_test_split(ratings_df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"Split ratings into training, validation, and test sets\"\"\"\n",
    "    # Ensure ratios sum to 1\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6\n",
    "    \n",
    "    # Split the data\n",
    "    train_data, temp_data = ratings_df.randomSplit([train_ratio, val_ratio + test_ratio], seed=seed)\n",
    "    \n",
    "    # Adjust validation ratio\n",
    "    val_adjusted_ratio = val_ratio / (val_ratio + test_ratio)\n",
    "    val_data, test_data = temp_data.randomSplit([val_adjusted_ratio, 1.0 - val_adjusted_ratio], seed=seed)\n",
    "    \n",
    "    # Cache the datasets\n",
    "    train_data.cache()\n",
    "    val_data.cache()\n",
    "    test_data.cache()\n",
    "    \n",
    "    # Display split sizes\n",
    "    train_count = train_data.count()\n",
    "    val_count = val_data.count()\n",
    "    test_count = test_data.count()\n",
    "    total = train_count + val_count + test_count\n",
    "    \n",
    "    print(f\"Training set: {train_count:,} ratings ({train_count/total*100:.2f}%)\")\n",
    "    print(f\"Validation set: {val_count:,} ratings ({val_count/total*100:.2f}%)\")\n",
    "    print(f\"Test set: {test_count:,} ratings ({test_count/total*100:.2f}%)\")\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Function to calculate and print evaluation metrics\n",
    "def evaluate_model(predictions, truth_col=\"rating\", pred_col=\"prediction\"):\n",
    "    \"\"\"Calculate and print RMSE and MAE for model predictions\"\"\"\n",
    "    evaluator_rmse = RegressionEvaluator(\n",
    "        metricName=\"rmse\", \n",
    "        labelCol=truth_col, \n",
    "        predictionCol=pred_col\n",
    "    )\n",
    "    \n",
    "    evaluator_mae = RegressionEvaluator(\n",
    "        metricName=\"mae\", \n",
    "        labelCol=truth_col, \n",
    "        predictionCol=pred_col\n",
    "    )\n",
    "    \n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "    mae = evaluator_mae.evaluate(predictions)\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    \n",
    "    return {\"RMSE\": rmse, \"MAE\": mae}\n",
    "\n",
    "# Baseline model: Global mean and bias model\n",
    "def train_baseline_models(train_data, val_data):\n",
    "    \"\"\"Train and evaluate baseline models\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Global mean model\n",
    "    global_mean = train_data.select(\"rating\").agg({\"rating\": \"avg\"}).collect()[0][0]\n",
    "    print(f\"Global mean rating: {global_mean:.4f}\")\n",
    "    \n",
    "    # Add global mean prediction column to validation data\n",
    "    val_global_mean = val_data.withColumn(\"prediction\", lit(global_mean))\n",
    "    \n",
    "    # Evaluate global mean model\n",
    "    print(\"Global Mean Model Performance:\")\n",
    "    global_mean_metrics = evaluate_model(val_global_mean)\n",
    "    \n",
    "    # Bias model: Calculate user and item biases\n",
    "    user_means = train_data.groupBy(\"userId\").agg({\"rating\": \"avg\"}).withColumnRenamed(\"avg(rating)\", \"user_mean\")\n",
    "    item_means = train_data.groupBy(\"movieId\").agg({\"rating\": \"avg\"}).withColumnRenamed(\"avg(rating)\", \"item_mean\")\n",
    "    \n",
    "    # Calculate biases (differences from global mean)\n",
    "    user_biases = user_means.withColumn(\"user_bias\", col(\"user_mean\") - global_mean)\n",
    "    item_biases = item_means.withColumn(\"item_bias\", col(\"item_mean\") - global_mean)\n",
    "    \n",
    "    # Add predictions to validation data\n",
    "    val_with_user = val_data.join(user_biases, \"userId\", \"left\")\n",
    "    val_with_user_item = val_with_user.join(item_biases, \"movieId\", \"left\")\n",
    "    \n",
    "    # Fill missing biases with 0\n",
    "    val_with_user_item = val_with_user_item.na.fill({\n",
    "        \"user_bias\": 0.0,\n",
    "        \"item_bias\": 0.0\n",
    "    })\n",
    "    \n",
    "    # Calculate bias prediction\n",
    "    val_with_predictions = val_with_user_item.withColumn(\n",
    "        \"prediction\", \n",
    "        global_mean + col(\"user_bias\") + col(\"item_bias\")\n",
    "    )\n",
    "    \n",
    "    # Evaluate bias model\n",
    "    print(\"\\nBias Model Performance:\")\n",
    "    bias_model_metrics = evaluate_model(val_with_predictions)\n",
    "    \n",
    "    print(f\"Baseline models trained and evaluated in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    return global_mean_metrics, bias_model_metrics, global_mean, user_biases, item_biases\n",
    "\n",
    "# Train ALS model with PySpark\n",
    "def train_als_model(train_data, val_data, rank=50, regParam=0.1, maxIter=10, seed=42):\n",
    "    \"\"\"Train an ALS model with specified parameters\"\"\"\n",
    "    print(f\"Training ALS model (rank={rank}, regParam={regParam}, maxIter={maxIter})...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create an ALS model\n",
    "    als = ALS(\n",
    "        rank=rank,\n",
    "        maxIter=maxIter,\n",
    "        regParam=regParam,\n",
    "        userCol=\"userId\",\n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\",\n",
    "        seed=seed,\n",
    "        nonnegative=True  # Enforce non-negative factors\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model = als.fit(train_data)\n",
    "    \n",
    "    # Make predictions on validation data\n",
    "    predictions = model.transform(val_data)\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"ALS Model Performance:\")\n",
    "    als_metrics = evaluate_model(predictions)\n",
    "    \n",
    "    print(f\"ALS model trained in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    return model, als_metrics\n",
    "\n",
    "# Function to tune ALS parameters\n",
    "def tune_als_model(train_data, val_data, ranks=[10, 50, 100], regParams=[0.01, 0.1, 1.0], maxIters=[5, 10]):\n",
    "    \"\"\"Find the best ALS parameters through grid search\"\"\"\n",
    "    print(\"Tuning ALS model parameters...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    # Create evaluator\n",
    "    evaluator = RegressionEvaluator(\n",
    "        metricName=\"rmse\", \n",
    "        labelCol=\"rating\", \n",
    "        predictionCol=\"prediction\"\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Grid search\n",
    "    for rank in ranks:\n",
    "        for regParam in regParams:\n",
    "            for maxIter in maxIters:\n",
    "                print(f\"Trying rank={rank}, regParam={regParam}, maxIter={maxIter}\")\n",
    "                \n",
    "                # Create ALS model\n",
    "                als = ALS(\n",
    "                    rank=rank,\n",
    "                    maxIter=maxIter,\n",
    "                    regParam=regParam,\n",
    "                    userCol=\"userId\",\n",
    "                    itemCol=\"movieId\",\n",
    "                    ratingCol=\"rating\",\n",
    "                    coldStartStrategy=\"drop\",\n",
    "                    seed=42,\n",
    "                    nonnegative=True\n",
    "                )\n",
    "                \n",
    "                # Train the model\n",
    "                model = als.fit(train_data)\n",
    "                \n",
    "                # Make predictions on validation data\n",
    "                predictions = model.transform(val_data)\n",
    "                \n",
    "                # Calculate RMSE\n",
    "                rmse = evaluator.evaluate(predictions)\n",
    "                \n",
    "                # Create MAE evaluator\n",
    "                evaluator_mae = RegressionEvaluator(\n",
    "                    metricName=\"mae\", \n",
    "                    labelCol=\"rating\", \n",
    "                    predictionCol=\"prediction\"\n",
    "                )\n",
    "                mae = evaluator_mae.evaluate(predictions)\n",
    "                \n",
    "                results.append({\n",
    "                    'rank': rank,\n",
    "                    'regParam': regParam,\n",
    "                    'maxIter': maxIter,\n",
    "                    'RMSE': rmse,\n",
    "                    'MAE': mae\n",
    "                })\n",
    "                \n",
    "                print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "                \n",
    "                # Check if this model is better\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_params = (rank, regParam, maxIter)\n",
    "                    best_model = model\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print best parameters\n",
    "    best_rank, best_regParam, best_maxIter = best_params\n",
    "    print(f\"\\nBest parameters: rank={best_rank}, regParam={best_regParam}, maxIter={best_maxIter}\")\n",
    "    print(f\"Best RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    print(f\"ALS parameter tuning completed in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Return best model and results\n",
    "    return best_model, results_df\n",
    "\n",
    "# Function for generating recommendations\n",
    "def generate_recommendations(model, movies_df, user_id, spark, n=10):\n",
    "    \"\"\"Generate movie recommendations for a specific user\"\"\"\n",
    "    # Get top N movie recommendations\n",
    "    user_recs = model.recommendForUserSubset(spark.createDataFrame([(user_id,)], [\"userId\"]), n)    \n",
    "    # Extract recommendations\n",
    "    if not user_recs.isEmpty():\n",
    "        recs = user_recs.collect()[0].recommendations\n",
    "        rec_movies = [(rec.movieId, rec.rating) for rec in recs]\n",
    "        \n",
    "        # Get movie details\n",
    "        rec_movie_ids = [rec[0] for rec in rec_movies]\n",
    "        movie_details = movies_df.filter(col(\"movieId\").isin(rec_movie_ids)).collect()\n",
    "        \n",
    "        # Create a dictionary for movie lookup\n",
    "        movie_dict = {movie.movieId: movie for movie in movie_details}\n",
    "        \n",
    "        # Format recommendations\n",
    "        formatted_recs = []\n",
    "        for movie_id, rating in rec_movies:\n",
    "            if movie_id in movie_dict:\n",
    "                movie = movie_dict[movie_id]\n",
    "                formatted_recs.append({\n",
    "                    \"movieId\": movie_id,\n",
    "                    \"title\": movie.title,\n",
    "                    \"genres\": movie.genres,\n",
    "                    \"predicted_rating\": rating\n",
    "                })\n",
    "        \n",
    "        return formatted_recs\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Function to save model and artifacts\n",
    "def save_model_artifacts(model, output_dir=\"models\"):\n",
    "    \"\"\"Save model and relevant artifacts for later use\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Save ALS model with overwrite option\n",
    "    model_path = os.path.join(output_dir, \"als_model\")\n",
    "    model.write().overwrite().save(model_path)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    return model_path\n",
    "\n",
    "# Main function to run the entire pipeline\n",
    "def main():\n",
    "    # Initialize Spark\n",
    "    spark = init_spark(memory=\"6g\")  # Adjust memory based on your system\n",
    "    \n",
    "    try:\n",
    "        # Load and prepare data\n",
    "        ratings_df, movies_df, n_users, n_movies = load_data(spark, \"ml-32m\", min_ratings=5)\n",
    "        \n",
    "        # Process movie features\n",
    "        movies_df = process_movie_features(spark, movies_df)\n",
    "        \n",
    "        # Split data\n",
    "        train_data, val_data, test_data = train_val_test_split(ratings_df)\n",
    "        \n",
    "        # Train baseline models\n",
    "        global_mean_metrics, bias_model_metrics, global_mean, user_biases, item_biases = train_baseline_models(train_data, val_data)\n",
    "        \n",
    "        # Train ALS model\n",
    "        als_model, als_metrics = train_als_model(train_data, val_data, rank=50, regParam=0.1, maxIter=10)\n",
    "        \n",
    "        # Save model\n",
    "        model_path = save_model_artifacts(als_model)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_predictions = als_model.transform(test_data)\n",
    "        print(\"\\nALS Model Performance on Test Set:\")\n",
    "        test_metrics = evaluate_model(test_predictions)\n",
    "        \n",
    "        # Generate example recommendations\n",
    "        sample_user_id = ratings_df.select(\"userId\").distinct().limit(1).collect()[0][0]\n",
    "        print(f\"\\nExample recommendations for user {sample_user_id}:\")\n",
    "        recs = generate_recommendations(als_model, movies_df, sample_user_id, spark, n=5)\n",
    "        for i, rec in enumerate(recs):\n",
    "            print(f\"{i+1}. {rec['title']} - Predicted rating: {rec['predicted_rating']:.2f}\")\n",
    "        \n",
    "        # Collect and print all metrics\n",
    "        all_metrics = {\n",
    "            \"Global Mean\": global_mean_metrics,\n",
    "            \"Bias Model\": bias_model_metrics,\n",
    "            \"ALS\": als_metrics,\n",
    "            \"ALS (Test)\": test_metrics\n",
    "        }\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        metrics_df = pd.DataFrame.from_dict(all_metrics, orient='index')\n",
    "        print(\"\\nModel Performance Summary:\")\n",
    "        print(metrics_df)\n",
    "        \n",
    "        # Save metrics\n",
    "        metrics_df.to_csv(\"model_metrics.csv\")\n",
    "        \n",
    "        print(\"\\nRecommendation model pipeline completed successfully!\")\n",
    "        \n",
    "    finally:\n",
    "        # Stop Spark session\n",
    "        spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from pyspark.sql.functions import lit\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sltd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
